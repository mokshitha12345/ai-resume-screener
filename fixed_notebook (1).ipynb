{"nbformat": 4, "nbformat_minor": 0, "metadata": {"colab": {"provenance": []}, "kernelspec": {"name": "python3", "display_name": "Python 3"}, "language_info": {"name": "python"}}, "cells": [{"cell_type": "code", "execution_count": 8, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "Lu1-qgGVx2th", "executionInfo": {"status": "ok", "timestamp": 1750428488794, "user_tz": -330, "elapsed": 12613, "user": {"displayName": "MINIMANURI MOKSHITHA SREE", "userId": "05541913864527527445"}}, "outputId": "e569e8cf-1836-40c1-fcfb-5505dc5135c2"}, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.46.0)\n", "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.11)\n", "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n", "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.2.0)\n", "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n", "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n", "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n", "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n", "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n", "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n", "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n", "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n", "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n", "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n", "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n", "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n", "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n", "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n", "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.0)\n", "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n", "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n", "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n", "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n", "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n", "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.4.0)\n", "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.52.4)\n", "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n", "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n", "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n", "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n", "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.33.0)\n", "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n", "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n", "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n", "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n", "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n", "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.43.0)\n", "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n", "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n", "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n", "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.3)\n", "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n", "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n", "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n", "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n", "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.6.15)\n", "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n", "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n", "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n", "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n", "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n", "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n", "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n", "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n", "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n", "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n", "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n", "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n", "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n", "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n", "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n", "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n", "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n", "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n", "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n", "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n", "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n", "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n", "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n", "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n", "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n", "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n", "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n", "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.25.1)\n"]}], "source": ["!pip install streamlit pyngrok PyPDF2 python-docx sentence-transformers pandas"]}, {"cell_type": "code", "source": ["import pandas as pd\n", "import random\n", "\n", "# Define job roles and skills\n", "job_data = {\n", "    \"Python Developer\": [\"Python\", \"Flask\", \"Django\", \"APIs\", \"SQL\", \"Pandas\"],\n", "    \"AI/ML Engineer\": [\"Machine Learning\", \"Deep Learning\", \"TensorFlow\", \"PyTorch\", \"NLP\", \"Computer Vision\"],\n", "    \"Data Scientist\": [\"Data Analysis\", \"Statistics\", \"Python\", \"R\", \"Scikit-learn\", \"SQL\"],\n", "    \"Data Analyst\": [\"Excel\", \"SQL\", \"Power BI\", \"Tableau\", \"Data Visualization\", \"Python\"],\n", "    \"Java Developer\": [\"Java\", \"Spring\", \"Hibernate\", \"REST APIs\", \"Microservices\", \"Maven\"],\n", "    \"C++ Developer\": [\"C++\", \"STL\", \"OOP\", \"Multithreading\", \"Algorithms\", \"Data Structures\"],\n", "    \"Software Engineer\": [\"Software Development\", \"Agile\", \"Git\", \"CI/CD\", \"Design Patterns\", \"Debugging\"],\n", "    \"Full Stack Developer\": [\"HTML\", \"CSS\", \"JavaScript\", \"React\", \"Node.js\", \"MongoDB\", \"Express\"],\n", "    \"Backend Developer\": [\"Java\", \"Node.js\", \"Django\", \"Databases\", \"APIs\", \"Microservices\"],\n", "    \"NLP Engineer\": [\"NLP\", \"Text Classification\", \"SpaCy\", \"Transformers\", \"BERT\", \"Sentiment Analysis\"],\n", "    \"Computer Vision Engineer\": [\"Image Processing\", \"OpenCV\", \"CNN\", \"YOLO\", \"Object Detection\", \"PyTorch\"]\n", "}\n", "\n", "rows = []\n", "for job, skills in job_data.items():\n", "    for _ in range(10):\n", "        # Matching pair (label=1)\n", "        resume = f\"Experienced in {', '.join(random.sample(skills, 4))}. Worked on {job.lower()} projects.\"\n", "        jd = f\"We are hiring a {job} with skills in {', '.join(random.sample(skills, 4))}.\"\n", "        rows.append((resume, jd, 1))\n", "\n", "        # Non-matching pair (label=0)\n", "        other_job = random.choice([j for j in job_data if j != job])\n", "        other_skills = job_data[other_job]\n", "        resume = f\"Skilled in {', '.join(random.sample(other_skills, 4))}. Background in {other_job.lower()}.\"\n", "        rows.append((resume, jd, 0))\n", "\n", "df = pd.DataFrame(rows, columns=[\"resume_text\", \"job_description\", \"label\"])\n", "df.to_csv(\"fine_tuning_resume_dataset.csv\", index=False)\n", "print(\"Dataset CSV created: fine_tuning_resume_dataset.csv\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "F63cYOTdzuoe", "executionInfo": {"status": "ok", "timestamp": 1750428498805, "user_tz": -330, "elapsed": 64, "user": {"displayName": "MINIMANURI MOKSHITHA SREE", "userId": "05541913864527527445"}}, "outputId": "2ed30a3e-df42-4c34-aa37-4039e314ff98"}, "execution_count": 9, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Dataset CSV created: fine_tuning_resume_dataset.csv\n"]}]}, {"cell_type": "code", "source": ["%%writefile app.py\n", "import streamlit as st\n", "from sentence_transformers import SentenceTransformer, util\n", "import PyPDF2\n", "from docx import Document\n", "from io import BytesIO\n", "import pandas as pd\n", "import time\n", "\n", "# Load model\n", "model = SentenceTransformer('fine_tuned_resume_model')\n", "\n", "# UI Config\n", "st.set_page_config(page_title=\"AI Resume Screener\", page_icon=\"\ud83d\udccb\", layout=\"wide\")\n", "\n", "# CSS\n", "st.markdown(\"\"\"\n", "<style>\n", "    .header {\n", "        background: linear-gradient(135deg, #6B73FF 0%, #000DFF 100%);\n", "        color: white;\n", "        padding: 2rem;\n", "        border-radius: 10px;\n", "        margin-bottom: 2rem;\n", "    }\n", "    .result-card {\n", "        border-radius: 10px;\n", "        padding: 1.5rem;\n", "        margin-bottom: 1rem;\n", "        box-shadow: 0 4px 6px rgba(0,0,0,0.1);\n", "        background-color: #f9f9f9;\n", "    }\n", "</style>\n", "\"\"\", unsafe_allow_html=True)\n", "\n", "# Extractors\n", "def extract_text_from_pdf(file):\n", "    with BytesIO(file.read()) as f:\n", "        reader = PyPDF2.PdfReader(f)\n", "        return \" \".join([page.extract_text() for page in reader.pages if page.extract_text()])\n", "\n", "def extract_text_from_docx(file):\n", "    with BytesIO(file.read()) as f:\n", "        doc = Document(f)\n", "        return \" \".join([para.text for para in doc.paragraphs if para.text])\n", "\n", "# Semantic Match\n", "def analyze_resume(resume_text, job_desc):\n", "    try:\n", "        emb_resume = model.encode(resume_text, convert_to_tensor=True)\n", "        emb_jd = model.encode(job_desc, convert_to_tensor=True)\n", "        score = util.pytorch_cos_sim(emb_resume, emb_jd).item()\n", "        score_percent = round(score * 100, 2)\n", "\n", "        recommendation = \"Strong Hire\" if score_percent >= 75 else \"Maybe\" if score_percent >= 50 else \"No\"\n", "        summary = f\"\"\"\n", "        1. **Match Score**: {score_percent}\n", "        2. **Recommendation**: {recommendation}\n", "        \"\"\"\n", "        return summary, score_percent, recommendation\n", "    except Exception as e:\n", "        return f\"Error: {str(e)}\", 0, \"Error\"\n", "\n", "# Main UI\n", "def main():\n", "    st.markdown(\"\"\"\n", "    <div class=\"header\">\n", "        <h1>\ud83d\udccb AI Resume Screener</h1>\n", "        <p>Semantic AI Matching \u2014 No API Key Required</p>\n", "    </div>\n", "    \"\"\", unsafe_allow_html=True)\n", "\n", "    uploaded_files = st.file_uploader(\"\ud83d\udcc1 Upload Resumes (PDF/DOCX)\", accept_multiple_files=True)\n", "    job_desc = st.text_area(\"\ud83d\udcdd Paste Job Description\", height=200, placeholder=\"Paste the job description here...\")\n", "\n", "    if st.button(\"\ud83d\udd0d Analyze Resumes\", type=\"primary\"):\n", "        if not uploaded_files:\n", "            st.error(\"Upload at least 1 resume\")\n", "        elif not job_desc.strip():\n", "            st.error(\"Enter a job description\")\n", "        else:\n", "            results = []\n", "            progress_bar = st.progress(0)\n", "\n", "            for i, file in enumerate(uploaded_files):\n", "                try:\n", "                    with st.expander(f\"\ud83d\udcc4 {file.name}\", expanded=True):\n", "                        with st.spinner(\"Analyzing...\"):\n", "                            text = extract_text_from_pdf(file) if file.name.endswith('.pdf') else extract_text_from_docx(file)\n", "                            analysis, score, rec = analyze_resume(text, job_desc)\n", "                            st.markdown(f\"\"\"<div class=\"result-card\">{analysis}</div>\"\"\", unsafe_allow_html=True)\n", "                            results.append({\"File Name\": file.name, \"Match Score (%)\": score, \"Recommendation\": rec})\n", "                    progress_bar.progress((i+1)/len(uploaded_files))\n", "                    time.sleep(1)\n", "                except Exception as e:\n", "                    st.error(f\"Failed to process {file.name}: {str(e)}\")\n", "\n", "            # Show table and download\n", "            if results:\n", "                df = pd.DataFrame(results)\n", "                st.markdown(\"### \ud83d\udcca Summary\")\n", "                st.dataframe(df)\n", "                csv = df.to_csv(index=False).encode(\"utf-8\")\n", "                st.download_button(\"\ud83d\udce5 Download Results as CSV\", csv, \"resume_scores.csv\", \"text/csv\")\n", "\n", "if __name__ == \"__main__\":\n", "    main()\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "qyV5_fPuyOSu", "executionInfo": {"status": "ok", "timestamp": 1750428502306, "user_tz": -330, "elapsed": 34, "user": {"displayName": "MINIMANURI MOKSHITHA SREE", "userId": "05541913864527527445"}}, "outputId": "5893968e-c84e-4997-d020-8aa3459d6591"}, "execution_count": 10, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Overwriting app.py\n"]}]}, {"cell_type": "code", "source": ["# Disable wandb to avoid API key prompt\n", "import os\n", "os.environ[\"WANDB_DISABLED\"] = \"true\"\n", "\n", "import csv\n", "from sentence_transformers import SentenceTransformer, InputExample, losses\n", "from torch.utils.data import DataLoader\n", "\n", "# Load pretrained model\n", "model = SentenceTransformer('all-MiniLM-L6-v2')\n", "\n", "# Load data from CSV\n", "train_examples = []\n", "with open('fine_tuning_resume_dataset.csv', 'r', encoding='utf-8') as f:\n", "    reader = csv.DictReader(f)\n", "    for row in reader:\n", "        train_examples.append(\n", "            InputExample(texts=[row['resume_text'], row['job_description']], label=float(row['label']))\n", "        )\n", "\n", "# Prepare DataLoader\n", "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n", "\n", "# Define loss function\n", "train_loss = losses.CosineSimilarityLoss(model)\n", "\n", "# Fine-tune the model\n", "model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=3, warmup_steps=100)\n", "\n", "# Save the fine-tuned model\n", "model.save('fine_tuned_resume_model')\n", "print(\"Fine-tuned model saved in 'fine_tuned_resume_model' folder\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 147, "referenced_widgets": ["6efb231c28fa4b258ade7f819b8d953b", "e3439a1160a049d49b47ce61f0169ab2", "ce6c0f07113444c9a8b42fec3ddac9f5", "d5c0b036c577443996c01aa10bc76229", "5430925eabd34e198e430014e4eb21af", "80bf981e5b574916bf724c776e3f5876", "eca69985cf8b442999ef61c0430e49e6", "21f36ce089fc405e85ce7a21133ca7c1", "b9671d97ac8c4865a175c1ec591b0f77", "13adf8b083334870afdfe13ac75792ba", "d18a53ad1ee84b3c9b18fe5f38d11b22"]}, "id": "aoc6ju8Wz45b", "executionInfo": {"status": "ok", "timestamp": 1750428577676, "user_tz": -330, "elapsed": 71393, "user": {"displayName": "MINIMANURI MOKSHITHA SREE", "userId": "05541913864527527445"}}, "outputId": "b153bd3e-56d8-4f79-b9dc-8d169fc569d1"}, "execution_count": 11, "outputs": [{"output_type": "stream", "name": "stderr", "text": ["Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n", "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"]}, {"output_type": "display_data", "data": {"text/plain": ["Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "6efb231c28fa4b258ade7f819b8d953b"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": ["\n", "    <div>\n", "      \n", "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n", "      [42/42 01:06, Epoch 3/3]\n", "    </div>\n", "    <table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", " <tr style=\"text-align: left;\">\n", "      <th>Step</th>\n", "      <th>Training Loss</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "  </tbody>\n", "</table><p>"]}, "metadata": {}}, {"output_type": "stream", "name": "stdout", "text": ["Fine-tuned model saved in 'fine_tuned_resume_model' folder\n"]}]}, {"cell_type": "code", "source": ["!ngrok config add-authtoken 2ylesPLb3NX9clFkxkbctvfDLWJ_2aTdMtmLiTLz7NctF8PmV"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "mwVcbj2-ybEJ", "executionInfo": {"status": "ok", "timestamp": 1750428585726, "user_tz": -330, "elapsed": 214, "user": {"displayName": "MINIMANURI MOKSHITHA SREE", "userId": "05541913864527527445"}}, "outputId": "c2fafa2b-950c-4034-cdee-c9c65f2210cd"}, "execution_count": 12, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"]}]}, {"cell_type": "markdown", "source": [], "metadata": {"id": "8LIXvnt0rJLz"}}, {"cell_type": "code", "source": ["from pyngrok import ngrok\n", "import time\n", "\n", "ngrok.kill()\n", "!streamlit run app.py &>/content/logs.txt &\n", "\n", "time.sleep(5)\n", "public_url = ngrok.connect(8501)\n", "print(\"\u2705 Your app is live at:\", public_url)"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "rvCTW97OyeIi", "executionInfo": {"status": "ok", "timestamp": 1750428594776, "user_tz": -330, "elapsed": 5449, "user": {"displayName": "MINIMANURI MOKSHITHA SREE", "userId": "05541913864527527445"}}, "outputId": "99f279ff-9690-48b9-b1fd-ceecb724b1ed"}, "execution_count": 13, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["\u2705 Your app is live at: NgrokTunnel: \"https://c711-35-232-155-235.ngrok-free.app\" -> \"http://localhost:8501\"\n"]}]}, {"cell_type": "code", "source": ["import json\n", "from google.colab import _message\n", "from google.colab import files\n", "\n", "# Step 1: Get current notebook content\n", "notebook = _message.blocking_request('get_ipynb')['ipynb']\n", "\n", "# Step 2: Remove corrupted widget metadata\n", "if 'widgets' in notebook.get('metadata', {}):\n", "    del notebook['metadata']['widgets']\n", "    print(\"\u2705 Removed 'widgets' metadata.\")\n", "else:\n", "    print(\"\u2139\ufe0f No 'widgets' metadata found.\")\n", "\n", "# Step 3: Save cleaned notebook\n", "output_path = '/content/fixed_notebook.ipynb'\n", "with open(output_path, 'w') as f:\n", "    json.dump(notebook, f)\n", "\n", "# Step 4: Download the cleaned notebook\n", "files.download(output_path)\n"], "metadata": {"id": "GhEQ65kJq5JH"}, "execution_count": null, "outputs": []}]}